{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Pkg\n",
    "\n",
    "#Pkg.add(\"ColorTypes\")\n",
    "\n",
    "using Images, FileIO, DataFrames, Optimisers, ProgressMeter, Flux\n",
    "using Flux:  onehotbatch, crossentropy\n",
    "\n",
    "using ColorTypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "function lazy_load_image_data(dir::String, label::Int)\n",
    "    files = readdir(dir; join=true)  # Get list of image files in directory\n",
    "\n",
    "    return (begin\n",
    "        img = Images.load(f)  # Load image\n",
    "\n",
    "        # Convert RGB image to Float32 and extract channels\n",
    "        img = Float32.(channelview(img))  # Converts to (C, H, W)\n",
    "\n",
    "        # Correct the shape to (H, W, C)\n",
    "        img = permutedims(img, (2, 3, 1))  # From (C, H, W) â†’ (H, W, C)\n",
    "\n",
    "        # Ensure batch dimension is last (H, W, C, B)\n",
    "        img = reshape(img, size(img, 1), size(img, 2), size(img, 3), 1)\n",
    "\n",
    "        # Return tuple (image, label)\n",
    "        (img, label)\n",
    "    end for f in files)  # Create a generator\n",
    "end\n",
    "\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fake_iter = lazy_load_image_data(\"data/train/FAKE\", 0)\n",
    "train_real_iter = lazy_load_image_data(\"data/train/REAL\", 1)\n",
    "test_fake_iter = lazy_load_image_data(\"data/test/FAKE\", 0)\n",
    "test_real_iter = lazy_load_image_data(\"data/test/REAL\", 1)\n",
    "\n",
    "# Combine the datasets by converting the lazy iterator into a list and then concatenating\n",
    "train_data = vcat(collect(train_fake_iter), collect(train_real_iter))\n",
    "test_data = vcat(collect(test_fake_iter), collect(test_real_iter))\n",
    "\n",
    "# Extract features and labels from the dataset\n",
    "X_train = [x for (x, _) in train_data]\n",
    "y_train = Flux.onehotbatch([y for (_, y) in train_data], 0:1)\n",
    "X_test = [x for (x, _) in test_data]\n",
    "y_test = Flux.onehotbatch([y for (_, y) in test_data], 0:1)\n",
    "\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "function create_cnn()\n",
    "    return Chain(\n",
    "        x -> permutedims(x, (2, 3, 1, 4)), # Swap dimensions to (H, W, C, Batch)\n",
    "        Conv((3,3), 3=>32, relu, pad = 1),    # First convolution layer (32 filters, 3x3 kernel)\n",
    "        MaxPool((2,2)),              # Max pooling layer\n",
    "        Conv((3,3), 32=>64, relu, pad = 1),   # Second convolution layer (64 filters, 3x3 kernel)\n",
    "        MaxPool((2,2)),              # Max pooling layer\n",
    "        Conv((3,3), 64=>128, relu, pad = 1),  # Third convolution layer (128 filters, 3x3 kernel)\n",
    "        MaxPool((2,2)),              # Max pooling layer\n",
    "        Flux.flatten,                     # Flatten the output of the convolution layers\n",
    "        Dense(128 * 4 * 4, 10),      # Dense layer to output 10 classes\n",
    "        softmax                     # Softmax activation to get probabilities\n",
    "    )\n",
    "end\n",
    "\n",
    "model = create_cnn()\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(x, y) = logitcrossentropy(model(x), y)\n",
    "optimizer = ADAM()\n",
    "opt_state = Optimisers.setup(Adam(), model)\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "batch_size = 32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: (32, 32, 3, 1)\n"
     ]
    }
   ],
   "source": [
    "x_sample, y_sample = first(train_fake_iter)\n",
    "println(\"Image shape: \", size(x_sample))  # Should be (H, W, C, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "function train_model!(model, train_X, train_Y, opt, epochs, batch_size)\n",
    "\n",
    "    # this is the data loader that will be used to load the data in batches\n",
    "    data_loader = Flux.DataLoader((train_X, train_Y), batchsize=batch_size, shuffle=true)\n",
    "    \n",
    "    # setting up the optimizer and list ot gather the loss\n",
    "    opt_state = Flux.setup(opt, model)  \n",
    "    total_loss = []\n",
    "\n",
    "    # training the model through all epochs\n",
    "    for epoch in 1:epochs\n",
    "        epoch_loss = 0\n",
    "        \n",
    "        # going through each batch\n",
    "        for (x, y) in data_loader\n",
    "            # calculating the gradient and updating the weights\n",
    "            gs = Flux.gradient(model -> Flux.Losses.crossentropy(model(x), y), model)[1]  \n",
    "            Flux.update!(opt_state, Flux.trainable(model), gs)\n",
    "\n",
    "            # updating the epoch loss for plotting later\n",
    "            epoch_loss += Flux.Losses.crossentropy(model(x), y)\n",
    "        end\n",
    "\n",
    "        println(\"Epoch $epoch complete\")\n",
    "        push!(total_loss, epoch_loss)\n",
    "\n",
    "    end\n",
    "    return total_loss\n",
    "\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "ArgumentError: no valid permutation of dimensions",
     "output_type": "error",
     "traceback": [
      "ArgumentError: no valid permutation of dimensions",
      "",
      "Stacktrace:",
      "  [1] permutedims(B::Vector{Array{Float32, 4}}, perm::NTuple{4, Int64})",
      "    @ Base ./multidimensional.jl:1631",
      "  [2] adjoint",
      "    @ ~/.julia/packages/Zygote/3To5I/src/lib/array.jl:100 [inlined]",
      "  [3] _pullback",
      "    @ ~/.julia/packages/ZygoteRules/CkVIK/src/adjoint.jl:67 [inlined]",
      "  [4] #25",
      "    @ ./In[13]:3 [inlined]",
      "  [5] _pullback(ctx::Zygote.Context{false}, f::var\"#25#26\", args::Vector{Array{Float32, 4}})",
      "    @ Zygote ~/.julia/packages/Zygote/3To5I/src/compiler/interface2.jl:0",
      "  [6] _applychain",
      "    @ ~/.julia/packages/Flux/3711C/src/layers/basic.jl:68 [inlined]",
      "  [7] _pullback(::Zygote.Context{false}, ::typeof(Flux._applychain), ::Tuple{var\"#25#26\", Conv{2, 4, typeof(relu), Array{Float32, 4}, Vector{Float32}}, MaxPool{2, 4}, Conv{2, 4, typeof(relu), Array{Float32, 4}, Vector{Float32}}, MaxPool{2, 4}, Conv{2, 4, typeof(relu), Array{Float32, 4}, Vector{Float32}}, MaxPool{2, 4}, typeof(Flux.flatten), Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}, typeof(softmax)}, ::Vector{Array{Float32, 4}})",
      "    @ Zygote ~/.julia/packages/Zygote/3To5I/src/compiler/interface2.jl:0",
      "  [8] Chain",
      "    @ ~/.julia/packages/Flux/3711C/src/layers/basic.jl:65 [inlined]",
      "  [9] _pullback(ctx::Zygote.Context{false}, f::Chain{Tuple{var\"#25#26\", Conv{2, 4, typeof(relu), Array{Float32, 4}, Vector{Float32}}, MaxPool{2, 4}, Conv{2, 4, typeof(relu), Array{Float32, 4}, Vector{Float32}}, MaxPool{2, 4}, Conv{2, 4, typeof(relu), Array{Float32, 4}, Vector{Float32}}, MaxPool{2, 4}, typeof(Flux.flatten), Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}, typeof(softmax)}}, args::Vector{Array{Float32, 4}})",
      "    @ Zygote ~/.julia/packages/Zygote/3To5I/src/compiler/interface2.jl:0",
      " [10] #29",
      "    @ ./In[17]:17 [inlined]",
      " [11] _pullback(ctx::Zygote.Context{false}, f::var\"#29#30\"{OneHotArrays.OneHotMatrix{UInt32, Vector{UInt32}}, Vector{Array{Float32, 4}}}, args::Chain{Tuple{var\"#25#26\", Conv{2, 4, typeof(relu), Array{Float32, 4}, Vector{Float32}}, MaxPool{2, 4}, Conv{2, 4, typeof(relu), Array{Float32, 4}, Vector{Float32}}, MaxPool{2, 4}, Conv{2, 4, typeof(relu), Array{Float32, 4}, Vector{Float32}}, MaxPool{2, 4}, typeof(Flux.flatten), Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}, typeof(softmax)}})",
      "    @ Zygote ~/.julia/packages/Zygote/3To5I/src/compiler/interface2.jl:0",
      " [12] pullback(f::Function, cx::Zygote.Context{false}, args::Chain{Tuple{var\"#25#26\", Conv{2, 4, typeof(relu), Array{Float32, 4}, Vector{Float32}}, MaxPool{2, 4}, Conv{2, 4, typeof(relu), Array{Float32, 4}, Vector{Float32}}, MaxPool{2, 4}, Conv{2, 4, typeof(relu), Array{Float32, 4}, Vector{Float32}}, MaxPool{2, 4}, typeof(Flux.flatten), Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}, typeof(softmax)}})",
      "    @ Zygote ~/.julia/packages/Zygote/3To5I/src/compiler/interface.jl:96",
      " [13] pullback",
      "    @ ~/.julia/packages/Zygote/3To5I/src/compiler/interface.jl:94 [inlined]",
      " [14] gradient(f::Function, args::Chain{Tuple{var\"#25#26\", Conv{2, 4, typeof(relu), Array{Float32, 4}, Vector{Float32}}, MaxPool{2, 4}, Conv{2, 4, typeof(relu), Array{Float32, 4}, Vector{Float32}}, MaxPool{2, 4}, Conv{2, 4, typeof(relu), Array{Float32, 4}, Vector{Float32}}, MaxPool{2, 4}, typeof(Flux.flatten), Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}, typeof(softmax)}})",
      "    @ Zygote ~/.julia/packages/Zygote/3To5I/src/compiler/interface.jl:153",
      " [15] #gradient#1",
      "    @ ~/.julia/packages/Flux/3711C/src/gradient.jl:44 [inlined]",
      " [16] gradient",
      "    @ ~/.julia/packages/Flux/3711C/src/gradient.jl:31 [inlined]",
      " [17] train_model!(model::Chain{Tuple{var\"#25#26\", Conv{2, 4, typeof(relu), Array{Float32, 4}, Vector{Float32}}, MaxPool{2, 4}, Conv{2, 4, typeof(relu), Array{Float32, 4}, Vector{Float32}}, MaxPool{2, 4}, Conv{2, 4, typeof(relu), Array{Float32, 4}, Vector{Float32}}, MaxPool{2, 4}, typeof(Flux.flatten), Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}, typeof(softmax)}}, train_X::Vector{Array{Float32, 4}}, train_Y::OneHotArrays.OneHotMatrix{UInt32, Vector{UInt32}}, opt::Adam{Float64, Tuple{Float64, Float64}, Float64}, epochs::Int64, batch_size::Int64)",
      "    @ Main ./In[17]:17",
      " [18] top-level scope",
      "    @ In[18]:1"
     ]
    }
   ],
   "source": [
    "loss_list = train_model!(model, X_train, y_train, optimizer, epochs, batch_size);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 starting...\n"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "DimensionMismatch: layer Conv((3, 3), 3 => 32, relu) expects size(input, 3) == 3, but got 32Ã—3Ã—32Ã—1 Array{Float32, 4}",
     "output_type": "error",
     "traceback": [
      "DimensionMismatch: layer Conv((3, 3), 3 => 32, relu) expects size(input, 3) == 3, but got 32Ã—3Ã—32Ã—1 Array{Float32, 4}",
      "",
      "Stacktrace:",
      "  [1] _conv_size_check",
      "    @ ~/.julia/packages/Flux/3711C/src/layers/conv.jl:500 [inlined]",
      "  [2] rrule",
      "    @ ~/.julia/packages/Flux/3711C/src/layers/conv.jl:503 [inlined]",
      "  [3] rrule",
      "    @ ~/.julia/packages/ChainRulesCore/U6wNx/src/rules.jl:138 [inlined]",
      "  [4] chain_rrule",
      "    @ ~/.julia/packages/Zygote/3To5I/src/compiler/chainrules.jl:233 [inlined]",
      "  [5] macro expansion",
      "    @ ~/.julia/packages/Zygote/3To5I/src/compiler/interface2.jl:0 [inlined]",
      "  [6] _pullback",
      "    @ ~/.julia/packages/Zygote/3To5I/src/compiler/interface2.jl:91 [inlined]",
      "  [7] Conv",
      "    @ ~/.julia/packages/Flux/3711C/src/layers/conv.jl:195 [inlined]",
      "  [8] _pullback(ctx::Zygote.Context{false}, f::Conv{2, 4, typeof(relu), Array{Float32, 4}, Vector{Float32}}, args::Array{Float32, 4})",
      "    @ Zygote ~/.julia/packages/Zygote/3To5I/src/compiler/interface2.jl:0",
      "  [9] _applychain",
      "    @ ~/.julia/packages/Flux/3711C/src/layers/basic.jl:68 [inlined]",
      " [10] _pullback(::Zygote.Context{false}, ::typeof(Flux._applychain), ::Tuple{var\"#19#20\", Conv{2, 4, typeof(relu), Array{Float32, 4}, Vector{Float32}}, MaxPool{2, 4}, Conv{2, 4, typeof(relu), Array{Float32, 4}, Vector{Float32}}, MaxPool{2, 4}, Conv{2, 4, typeof(relu), Array{Float32, 4}, Vector{Float32}}, MaxPool{2, 4}, typeof(Flux.flatten), Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}, typeof(softmax)}, ::Array{Float32, 4})",
      "    @ Zygote ~/.julia/packages/Zygote/3To5I/src/compiler/interface2.jl:0",
      " [11] Chain",
      "    @ ~/.julia/packages/Flux/3711C/src/layers/basic.jl:65 [inlined]",
      " [12] #21",
      "    @ ./In[12]:11 [inlined]",
      " [13] _pullback(ctx::Zygote.Context{false}, f::var\"#21#23\"{Int64, Array{Float32, 4}}, args::Chain{Tuple{var\"#19#20\", Conv{2, 4, typeof(relu), Array{Float32, 4}, Vector{Float32}}, MaxPool{2, 4}, Conv{2, 4, typeof(relu), Array{Float32, 4}, Vector{Float32}}, MaxPool{2, 4}, Conv{2, 4, typeof(relu), Array{Float32, 4}, Vector{Float32}}, MaxPool{2, 4}, typeof(Flux.flatten), Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}, typeof(softmax)}})",
      "    @ Zygote ~/.julia/packages/Zygote/3To5I/src/compiler/interface2.jl:0",
      " [14] pullback(f::Function, cx::Zygote.Context{false}, args::Chain{Tuple{var\"#19#20\", Conv{2, 4, typeof(relu), Array{Float32, 4}, Vector{Float32}}, MaxPool{2, 4}, Conv{2, 4, typeof(relu), Array{Float32, 4}, Vector{Float32}}, MaxPool{2, 4}, Conv{2, 4, typeof(relu), Array{Float32, 4}, Vector{Float32}}, MaxPool{2, 4}, typeof(Flux.flatten), Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}, typeof(softmax)}})",
      "    @ Zygote ~/.julia/packages/Zygote/3To5I/src/compiler/interface.jl:96",
      " [15] pullback",
      "    @ ~/.julia/packages/Zygote/3To5I/src/compiler/interface.jl:94 [inlined]",
      " [16] gradient(f::Function, args::Chain{Tuple{var\"#19#20\", Conv{2, 4, typeof(relu), Array{Float32, 4}, Vector{Float32}}, MaxPool{2, 4}, Conv{2, 4, typeof(relu), Array{Float32, 4}, Vector{Float32}}, MaxPool{2, 4}, Conv{2, 4, typeof(relu), Array{Float32, 4}, Vector{Float32}}, MaxPool{2, 4}, typeof(Flux.flatten), Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}, typeof(softmax)}})",
      "    @ Zygote ~/.julia/packages/Zygote/3To5I/src/compiler/interface.jl:153",
      " [17] #gradient#1",
      "    @ ~/.julia/packages/Flux/3711C/src/gradient.jl:44 [inlined]",
      " [18] gradient(f::Function, args::Chain{Tuple{var\"#19#20\", Conv{2, 4, typeof(relu), Array{Float32, 4}, Vector{Float32}}, MaxPool{2, 4}, Conv{2, 4, typeof(relu), Array{Float32, 4}, Vector{Float32}}, MaxPool{2, 4}, Conv{2, 4, typeof(relu), Array{Float32, 4}, Vector{Float32}}, MaxPool{2, 4}, typeof(Flux.flatten), Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}, typeof(softmax)}})",
      "    @ Flux ~/.julia/packages/Flux/3711C/src/gradient.jl:31",
      " [19] top-level scope",
      "    @ In[12]:11"
     ]
    }
   ],
   "source": [
    "for epoch in 1:epochs\n",
    "    println(\"Epoch $epoch starting...\")\n",
    "\n",
    "    # Progress bar for training\n",
    "    prog = ProgressUnknown(\"Training Progress:\")\n",
    "\n",
    "    # Training on batches of data\n",
    "    for (x, y) in train_data\n",
    "        \n",
    "        # Compute gradients\n",
    "        grads = Flux.gradient(m -> loss(m(x), y), model)\n",
    "\n",
    "        # Update model parameters\n",
    "        Flux.update!(optimizer, model, grads)\n",
    "\n",
    "        next!(prog)  # Update the progress bar\n",
    "    end\n",
    "\n",
    "    println(\"\\nEpoch $epoch complete\")\n",
    "\n",
    "    # Optional: Evaluate on validation set (here we use the test data as an example)\n",
    "    if epoch % 1 == 0  # Perform validation every epoch\n",
    "        val_loss = mean(loss(model(x_val), y_val) for (x_val, y_val) in test_data)\n",
    "        println(\"Validation Loss after Epoch $epoch: $val_loss\")\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function accuracy(data)\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for (x, y) in data\n",
    "        preds = Flux.onecold(model(x))\n",
    "        labels = Flux.onecold(y)\n",
    "        correct += sum(preds .== labels)\n",
    "        total += length(labels)\n",
    "    end\n",
    "    return correct / total\n",
    "end\n",
    "\n",
    "test_acc = accuracy(test_data)\n",
    "println(\"Test Accuracy: \", test_acc)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.2",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
